TIDY!!!
each variable forms a column
each observation forms a row
each table/file stores data about one kind of observation




check to see if file exists:
if(!file.exists("some_file")){
    dir.create("some_file")
}


download.file(url, destination, method)
https method = curl


dateDownloaded <- date()

read.table()
read.csv()
read.xlsx() / read.xslx@()
consider optional arguments!!!!


XLConnect package
xmls are accessed like lists : rootNode[[1]][[1]]
xmlSapply(file, fn)
consider XPath package
xpathSApply(rootNode, "//name", xmlValue)
xpathSApply(website, "//li[@class='score']", xmlValue


jsonlite package
jsonData <- fromJSON("some_website")
names(jsonData$owner)

convert to/from JSON
myjson <- toJSON(iris, pretty = T)
iris2 <- fromJson(myjson)


Data.Table
library(data.table)
DF = data.frame(x=rnorm(9), y=rep(c("a", "b", "c"), each=3), z=rnorm(9))
head(DF)

tables() #list tables in memory

DT[ , list(mean(x), sum(y))]
DT[ , table(y)]

DT[ , m:={tmp <- (x+z); log2(tmp + 5)}]
DT[ , a:= x > 0]
DT[ , b:= mean(x+w), by = a ]

DT[ , .N, by = x] # count numbert of times, divided by x

setKey(DT, x) <- sets default argument
setkey(DT1, x); setkey(DT2, x)
merge(DT1, DT2)

ucscDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(uscsDb, "show databases;"); dbDisconnect(uscsDb);

dbListFields()
dbGetQuery()
dbReadTable()
dbSendQuery()


Hdf5
h5file = h5createFile("example.h5")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")

> A = matrix(1:10, nr= 5)
> h5write(A, "example.h5", "foo/A")
> B = array(seq(0.1, 2.0, by = 0.1), dim = c(5, 2, 2))
> attr(B, "scale") <- "liter"
> h5write(B, "example.h5", "foo/foobaa/B")
> h5ls("example.h5")

> readA = h5read("example.h5", "foo/A")
> readA

> h5write(c(12, 13,14), "example.h5", "foo/A", index = list(1:3, 1))
> readA = h5read("example.h5", "foo/A")
> readA

getting data off webpages
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode

html <- htmlTreeParse(usrl, useInternalNodes = T)
xpathSApply(html, "//title', xmlValu)
xpathSApply(html, "td[@id='col-citedby']", xmlValue)

httr
library(httr)
html2 = GET(url)
content2 = content(html2, as = "text")
parsedHtml = htmlParse(content2, asText = T)
xpathSApply(parsedHtml, "//title", xmlValue)

can authenticate using httr(url(
pg2 = GET("URL", authenticate("user", "passwd"))

get data from APIs (like twitter)
myapp = oath_app("twitter", key = "yourConsumerKey", secret = "yourConsumerSecret")
sig = sign_oath1.0(myapp, token = "yourToken", token_secret = "yourTokenSecret")
homeTL = GET("url/file.json", sig)

json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1, 1:4]


fname <- "wksst8110.for"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")

# column sequence: 5x empty space, SST column, SSTA column
col_seq <- c(-5, 4, 4)

# rows: skip first four lines 
# cols (left to right): 
#   empty space (-1) 
#   nine characters (9) 
#   etc.
df <- read.fwf(fname, 
               widths = c(-1, 9, col_seq, col_seq, col_seq, col_seq),
               skip = 4)
answer5 <- sum(df[, 4])

SUBSETTING and SORTING

& and
| or
which()
order() # x[order(x$var1, x$var3),]

library(plyr)
arrange(x, var1)

rbind()
cbind()

tabel(data, useNA= 'ifany') 
sum(is.na()
any(is.na())
all(x > 0)

table(x$zipcode %in% c("12345", "67890"))

x <- c(1, 3, 5, 7, 9,)
seq(along = x)

ifelse(zipcode < 0 , T, F)
x <- cut(zipcode, breaks = quantile(zipcode))

library(Hmisc)
cut2(zips, g = 4)
factor(zipcode)

library(plyr)
mutate(old.df, new.var)

library(reshape2)
carMelt <- melt(mtcars, id = c("carname", "gear", "cyl"), measure.var = c("mpg", "hp"))
cylCast <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyl ~ variable, mean)

tapply(InsectSprays$count, InspectSpray$spray, sum)
spIns = split(InsectSpray$count, InspectSprays$spray) # split
sprCoutn = lapply(spIns, sum) # apply function
unlist(sprCount) # combine

sapply(spIns, sum) # apply and combine

ddply(InspectSprays, .(spray), summarize, sum = sum(count))
spraySums <- ddply(InsectSprays, .(spray), summarize, sum = ave(count, FUN = sum))



DPLYR
library(dplyr)

chicago <- readRDS("chicago.rds")

head(select(chicago, city:dptp)) # return all columns between city and dptp
head(select(chicago, -(city:dptp)) # return all coumns but those between city and dptp

chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)

chicago <- arrange(chicago, desc(date))

chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)

chicago <- mutate(chicago, tempcat = factor(1 * (tmpd >80), labels = c("cold", "hot"))
hotcold <- group_by(chicago, tmepcat)
summarize(hotcold, pm25 = mean(pm25, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))

chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
years <- group_by(chicgo, year)

%>% pipeline

chicago %>% mutate(month = as.POSIXlt(date)$mon +!) %>% group_by(month) %>% 
	summraize(pm25 = mena(pm25, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))



MERGING

merge(df1, df2, by.x = " ", by.y = " ", all = T)

library(plyr)
join(df1, df2) # faster but dumber

dList = list(df1, df2, df3)
join_all(dList)

DPLYR

select() # COLUMNS select(df, var1, var2, ...) 
# no need for df$var1... will also reorder columns
# can specify columns as var1:var3, or inreverse var3:var1, onmit -var1

filter() # ROWS filter(df, var1 == "some_value" | var2 <= "some_more")
# filter(df, !is.na(var1))

arrange() # arrange ROWS
# arrange(df, desc(var1), var2 ...) arrange by var1 descending, then var2 ascending

mutate() # add a column to a df
# mutate(df, new_var1 = 1:100, new_var2 = sqrt(new_var1))

summarize() # summarize(), collapses the dataset to a single row
# summarize(df, var3 = mean(var1))

tbl_df() # create a table from a df

group_by() # group_by() takes an existing tbl and converts it into a grouped tbl where 
# operations are performed "by group". ungroup() removes grouping.
# any operation we apply to the grouped data will take place on a per package basis

quantile(df$var1, probs = 0.99) will return the value above 99%

View() # opens a new table to view complete contents

%>% chain / pipe

TIDYING

gather() # Gather takes multiple columns and collapses into key-value pairs, duplicating all 
# other columns as needed. You use gather() when you notice that you have columns that are not 
# variables.

seperate() # separate() turns a single character column into multiple columns

spread() # Spread a key-value pair across multiple columns.

bind_rows() # binds df by row

strsplit
tolower()
toupper()
sub()
gsub()
grep()
grel() # logical

library(stringr)
nchar()
substr()
paste()
paste0()
strtrim()

NAMING VARIABLES
	all lowercase
	descriptive
	unique
	no underscores, dots or whitespace
	character variables should be factors, typed out

REGULAR EXPRESSIONS for grep grepl sub gsub

^i think = i think at the beginning of a line
morning$ = morning at the end of a line
[Bb][Uu][Ss][Hh] = will match all cases of the word bush
[0-9][a-zA-Z] = will specify a range
[^.?]$ = not ending in ? or .
. = any character
| = or
? = optional [Gg]eorge( [Ww]\.)? [Bb]ush #escaped out period
* = any number of
+ = atleast one of
[Bb]ush{ +[^ ]+ +){1,5} debate = Bush with 1-5 words and then debate
m,n = atleast m but not more than n
m = exactly m
m, = atlaeast m
 +([a-zA-Z+) +\1 + = match two words in a row.
* = greedy match
^(.*?)s$ = not greedy

DATE

date()
Sys.Date
as.date(x, "%d%b%Y")

format(date(), "%a %b %d")
%d day as number
%a abbreviated weekday
%A unabbreviated
%m month as a number
%b abbreviated month
%B unabbrevaiated month
%y 2 digit year
%Y four digit year


weekdays
months()
julian()

library(lubridate);
ymd("20140108") 
mdy()
dmy()
ymd_hms() # hours minute seconds
today() # date
now() # date plus time



